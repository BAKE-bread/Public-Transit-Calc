# CUDA 动态负载均衡演示

本项目通过一个 C++/CUDA 程序，演示了在处理计算量不均衡的任务时，GPU 上的三种不同负载均衡策略：静态调度、动态调度和层级动态调度。您也可以通过该程序学习 CUDA 程序的编写方法。

代码旨在处理一个典型的“长尾”工作负载：其中 90% 的任务计算量很小，而 10% 的任务计算量非常大。通过比较三种策略的运行时间，可以直观地理解负载均衡对 GPU 程序性能的影响。

## 环境要求

在编译和运行本程序前，请确保您的系统已安装：

1.  一块支持 CUDA 的 **NVIDIA GPU**
2.   **NVIDIA 显卡驱动**
3.  **NVIDIA CUDA Toolkit** (必须包含 `nvcc` 编译器)

您可以在终端输入 `nvcc --version` 来检查 CUDA Toolkit 是否已正确安装。

## 如何编译

1.  目标文件是 `balanced_cuda.cu` ，打开终端，进入文件所在目录。
2.  运行以下命令进行编译：

    ```bash
    nvcc -o balanced_cuda balanced_cuda.cu
    ```
    这会生成一个名为 `balanced_cuda` 的可执行文件。

    **（可选）性能优化：** 为了获得最佳性能，建议在编译时指定您 GPU 的计算能力架构。例如，可以使用以下命令（具体sm数量需按实际情况填写）：
    ```bash
    nvcc -arch=sm_86 -o balanced_cuda balanced_cuda.cu
    ```

## 如何运行

该程序需要一个命令行参数来选择不同的调度模式。

* **运行静态调度模式：**
    ```bash
    ./balanced_cuda static
    ```

* **运行动态调度模式：**
    ```bash
    ./balanced_cuda dynamic
    ```

* **运行层级动态调度模式：**
    ```bash
    ./balanced_cuda hierarchical
    ```

## 结果分析

程序运行后会输出对应模式的执行时间。通常会观察到以下性能排序：

1.  **静态 (Static)**: **速度最慢**。
    * **原因**: 任务被预先静态分配给所有线程。如果某个线程块不幸分到了大量耗时的“重”任务，其他提前完成任务的线程块只能空闲等待，导致 GPU 资源严重浪费。

2.  **动态 (Dynamic)**: **速度比静态快得多，可能接近于层级**。
    * **原因**: 线程完成一个任务后，会通过全局的原子计数器主动领取下一个任务。这确保了只要还有任务未完成，GPU 核心就不会闲置，从而实现了有效的负载均衡。它的主要瓶颈在于所有线程都在争抢同一个全局计数器，会产生一定的“原子操作争用”开销。

3.  **层级 (Hierarchical)**: **速度通常最快**。
    * **原因**: 这是对动态调度的优化。它不是让每个线程都去请求任务，而是让一个 Warp (一组32个线程) 的“领头线程”一次性为整个 Warp 领取一批任务。这大大减少了对全局原子计数器的访问频率和竞争，在实现负载均衡的同时，降低了调度开销，因此性能通常是最好的。
